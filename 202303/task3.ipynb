{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "aae0f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv', sep='\\t', header=None)\n",
    "test_data = pd.read_csv('test.csv', sep='\\t', header=None)\n",
    "train_data.columns = [\"text\",\"label\"]\n",
    "test_data.columns = [\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "43d3fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_stopwords = ' '.join(pd.read_csv('https://mirror.coggle.club/stopwords/baidu_stopwords.txt', header=None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "465dd71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def cut_by_jieba(sentence):\n",
    "    segs = list(jieba.cut(sentence))\n",
    "    filtered_segs = [x for x in segs if x not in cn_stopwords]\n",
    "    seg_string = \" \".join(filtered_segs)\n",
    "    return seg_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d5af78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"text_segs\"] = train_data[\"text\"].apply(cut_by_jieba)\n",
    "test_data[\"text_segs\"] = test_data[\"text\"].apply(cut_by_jieba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63b08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(object):\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for item in self.data[\"text_segs\"]:\n",
    "            yield item.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35de2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "sentences = MyDataset(train_data)\n",
    "model_50 = gensim.models.Word2Vec(sentences=sentences,vector_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c721f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_70 = gensim.models.Word2Vec(sentences=sentences,vector_size=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a124f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_100 = gensim.models.Word2Vec(sentences=sentences,vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def05fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_120 = gensim.models.Word2Vec(sentences=sentences,vector_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ffedc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/1690 is 播放\n",
      "word #1/1690 is 一个\n",
      "word #2/1690 is 想\n",
      "word #3/1690 is 月\n",
      "word #4/1690 is ，\n",
      "word #5/1690 is 听\n",
      "word #6/1690 is 明天\n",
      "word #7/1690 is 号\n",
      "word #8/1690 is 找\n",
      "word #9/1690 is 提醒\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(model_50.wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(model_50.wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0042c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#平均句向量\n",
    "def sent_vec(sent,w2v=None):\n",
    "    sent_segs = sent.split()\n",
    "    #对付NaN\n",
    "    mean_sent_vec = np.zeros((w2v.vector_size,),dtype=\"float32\")+0.00001\n",
    "    for seg in sent_segs:\n",
    "        if seg in w2v:\n",
    "            mean_sent_vec += w2v[seg]\n",
    "    #对付inf,因为有的句子分词+去停词后为空字符串\n",
    "    if len(sent_segs) == 0:\n",
    "        mean_sent_vec = mean_sent_vec\n",
    "    else:\n",
    "        mean_sent_vec = mean_sent_vec/len(sent_segs)\n",
    "    mean_sent_vec = mean_sent_vec.tolist()\n",
    "    return mean_sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e5a7336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#步骤3\n",
    "train_data[\"text_w2v_50\"] = train_data[\"text_segs\"].apply(sent_vec,w2v=model_50.wv)\n",
    "train_data[\"text_w2v_70\"] = train_data[\"text_segs\"].apply(sent_vec,w2v=model_70.wv)\n",
    "train_data[\"text_w2v_100\"] = train_data[\"text_segs\"].apply(sent_vec,w2v=model_100.wv)\n",
    "train_data[\"text_w2v_120\"] = train_data[\"text_segs\"].apply(sent_vec,w2v=model_120.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0586dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"text_w2v_50\"] = test_data[\"text_segs\"].apply(sent_vec,w2v=model_50.wv)\n",
    "test_data[\"text_w2v_70\"] = test_data[\"text_segs\"].apply(sent_vec,w2v=model_70.wv)\n",
    "test_data[\"text_w2v_100\"] = test_data[\"text_segs\"].apply(sent_vec,w2v=model_100.wv)\n",
    "test_data[\"text_w2v_120\"] = test_data[\"text_segs\"].apply(sent_vec,w2v=model_120.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7258fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(X,Y,vector_size=50):\n",
    "    removed_row = []\n",
    "    row_count = 0\n",
    "    for row in X:\n",
    "        zero_count = 0\n",
    "        for col in row:\n",
    "            if col == 0.0:\n",
    "                zero_count += 1\n",
    "        if zero_count == vector_size:\n",
    "            removed_row.append(row_count)\n",
    "        row_count += 1\n",
    "    start = 0\n",
    "    for _id in removed_row:\n",
    "        X = np.delete(X,_id-start,axis=0)\n",
    "        Y = np.delete(Y,_id-start,axis=0)\n",
    "        start += 1\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0b849ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f9f8d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_50 = LogisticRegression()\n",
    "lr_70 = LogisticRegression()\n",
    "lr_100 = LogisticRegression()\n",
    "lr_120 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "44b760b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12100, 50) (12100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\envs\\paddle\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_50 = np.array(train_data[\"text_w2v_50\"].tolist()).reshape(len(train_data[\"text_w2v_50\"]),50)\n",
    "Y_50 = train_data[\"label\"].to_numpy()\n",
    "print(X_50.shape,Y_50.shape)\n",
    "# X,Y = remove_nan(X,Y,vector_size=50)\n",
    "# print(X.shape,Y.shape)\n",
    "lr_50.fit(X_50,Y_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d45b8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_50 = np.array(test_data[\"text_w2v_50\"].tolist()).reshape(len(test_data[\"text_w2v_50\"]),50)\n",
    "Y_pred_50 = lr_50.predict(X_pred_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7a414cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12100, 70) (12100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\envs\\paddle\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_70 = np.array(train_data[\"text_w2v_70\"].tolist()).reshape(len(train_data[\"text_w2v_70\"]),70)\n",
    "Y_70 = train_data[\"label\"].to_numpy()\n",
    "print(X_70.shape,Y_70.shape)\n",
    "# X,Y = remove_nan(X,Y,vector_size=50)\n",
    "# print(X.shape,Y.shape)\n",
    "lr_70.fit(X_70,Y_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5a7d84cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_70 = np.array(test_data[\"text_w2v_70\"].tolist()).reshape(len(test_data[\"text_w2v_70\"]),70)\n",
    "Y_pred_70 = lr_70.predict(X_pred_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2090d1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12100, 100) (12100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\envs\\paddle\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_100 = np.array(train_data[\"text_w2v_100\"].tolist()).reshape(len(train_data[\"text_w2v_100\"]),100)\n",
    "Y_100 = train_data[\"label\"].to_numpy()\n",
    "print(X_100.shape,Y_100.shape)\n",
    "# X,Y = remove_nan(X,Y,vector_size=50)\n",
    "# print(X.shape,Y.shape)\n",
    "lr_100.fit(X_100,Y_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eae4db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_100 = np.array(test_data[\"text_w2v_100\"].tolist()).reshape(len(test_data[\"text_w2v_100\"]),100)\n",
    "Y_pred_100 = lr_100.predict(X_pred_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "64f39a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12100, 120) (12100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\envs\\paddle\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_120 = np.array(train_data[\"text_w2v_120\"].tolist()).reshape(len(train_data[\"text_w2v_120\"]),120)\n",
    "Y_120 = train_data[\"label\"].to_numpy()\n",
    "print(X_120.shape,Y_120.shape)\n",
    "# X,Y = remove_nan(X,Y,vector_size=50)\n",
    "# print(X.shape,Y.shape)\n",
    "lr_120.fit(X_120,Y_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "76a9349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_120 = np.array(test_data[\"text_w2v_120\"].tolist()).reshape(len(test_data[\"text_w2v_120\"]),120)\n",
    "Y_pred_120 = lr_120.predict(X_pred_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "81949232",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Y_pred_50\"] = Y_pred_50\n",
    "test_data[\"Y_pred_70\"] = Y_pred_70\n",
    "test_data[\"Y_pred_100\"] = Y_pred_100\n",
    "test_data[\"Y_pred_120\"] = Y_pred_120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ec14456c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_segs</th>\n",
       "      <th>text_w2v_50</th>\n",
       "      <th>text_w2v_70</th>\n",
       "      <th>text_w2v_100</th>\n",
       "      <th>text_w2v_120</th>\n",
       "      <th>Y_pred_50</th>\n",
       "      <th>Y_pred_70</th>\n",
       "      <th>Y_pred_100</th>\n",
       "      <th>Y_pred_120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>回放CCTV2的消费主张</td>\n",
       "      <td>回放 CCTV2 消费</td>\n",
       "      <td>[0.036894213408231735, -0.09735322743654251, 0...</td>\n",
       "      <td>[0.15702958405017853, -0.02909264713525772, -0...</td>\n",
       "      <td>[-0.037246935069561005, 0.11769197136163712, 0...</td>\n",
       "      <td>[0.009291189722716808, 0.10824751853942871, 0....</td>\n",
       "      <td>Video-Play</td>\n",
       "      <td>Video-Play</td>\n",
       "      <td>Video-Play</td>\n",
       "      <td>Video-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>给我打开玩具房的灯</td>\n",
       "      <td>打开 玩具 房 灯</td>\n",
       "      <td>[0.053586602210998535, -0.09181060642004013, 0...</td>\n",
       "      <td>[0.1797219067811966, -0.005513092502951622, -0...</td>\n",
       "      <td>[-0.0409448966383934, 0.1435110867023468, 0.02...</td>\n",
       "      <td>[0.013976670801639557, 0.14177896082401276, 0....</td>\n",
       "      <td>HomeAppliance-Control</td>\n",
       "      <td>HomeAppliance-Control</td>\n",
       "      <td>HomeAppliance-Control</td>\n",
       "      <td>HomeAppliance-Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>循环播放赵本山的小品相亲来听</td>\n",
       "      <td>循环 播放 赵本山 小品 相亲 听</td>\n",
       "      <td>[0.06058083102107048, -0.027346991002559662, -...</td>\n",
       "      <td>[0.24930541217327118, 0.07945393770933151, -0....</td>\n",
       "      <td>[-0.030159713700413704, 0.1654077023267746, -0...</td>\n",
       "      <td>[-0.01383722573518753, 0.12671895325183868, 0....</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15号上午10点带孩子去海洋馆的行程帮我制定下。</td>\n",
       "      <td>15 号 上午 10 点带 孩子 海洋馆 行程 制定 。</td>\n",
       "      <td>[0.10507967323064804, -0.3613370656967163, 0.1...</td>\n",
       "      <td>[0.30579033493995667, -0.15630006790161133, 0....</td>\n",
       "      <td>[-0.11538441479206085, 0.2785932123661041, 0.1...</td>\n",
       "      <td>[0.05573185160756111, 0.32761403918266296, 0.0...</td>\n",
       "      <td>Alarm-Update</td>\n",
       "      <td>Alarm-Update</td>\n",
       "      <td>Alarm-Update</td>\n",
       "      <td>Alarm-Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>把智能扫地机器人关掉</td>\n",
       "      <td>智能 扫地 机器人 关掉</td>\n",
       "      <td>[0.07013531774282455, -0.10136409103870392, 0....</td>\n",
       "      <td>[0.20975342392921448, -0.004705200903117657, -...</td>\n",
       "      <td>[-0.05659368261694908, 0.1639595478773117, 0.0...</td>\n",
       "      <td>[0.012684157118201256, 0.1588975340127945, 0.0...</td>\n",
       "      <td>HomeAppliance-Control</td>\n",
       "      <td>HomeAppliance-Control</td>\n",
       "      <td>HomeAppliance-Control</td>\n",
       "      <td>HomeAppliance-Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>是否能找一首2019年的抖音歌曲播放下呢</td>\n",
       "      <td>找 一首 2019 抖音 歌曲 播放</td>\n",
       "      <td>[0.048687893897295, -0.06284000724554062, -0.0...</td>\n",
       "      <td>[0.4206104576587677, 0.10067712515592575, -0.3...</td>\n",
       "      <td>[-0.0762188658118248, 0.25765904784202576, 0.0...</td>\n",
       "      <td>[0.00036368612200021744, 0.2149602621793747, 0...</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>下午三点有哪个台放大话西游吗帮我看下</td>\n",
       "      <td>下午 三点 台放 大话西游</td>\n",
       "      <td>[0.10081005096435547, -0.16935856640338898, 0....</td>\n",
       "      <td>[0.19554200768470764, -0.038734305649995804, -...</td>\n",
       "      <td>[-0.051506027579307556, 0.166267529129982, 0.0...</td>\n",
       "      <td>[0.01222950592637062, 0.16824771463871002, 0.0...</td>\n",
       "      <td>Alarm-Update</td>\n",
       "      <td>Alarm-Update</td>\n",
       "      <td>Alarm-Update</td>\n",
       "      <td>Alarm-Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>随机播放一首古筝弹奏的曲子可以吗</td>\n",
       "      <td>随机 播放 一首 古筝 弹奏 曲子</td>\n",
       "      <td>[0.04146405681967735, -0.005537357181310654, -...</td>\n",
       "      <td>[0.304779976606369, 0.108954519033432, -0.2450...</td>\n",
       "      <td>[-0.041685521602630615, 0.16562624275684357, 5...</td>\n",
       "      <td>[0.0006796050001867115, 0.1478983461856842, 0....</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "      <td>Music-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>美食纪录片螃蟹的征途给我找一下</td>\n",
       "      <td>美食 纪录片 螃蟹 征途 找</td>\n",
       "      <td>[0.04323325678706169, -0.07966790348291397, 0....</td>\n",
       "      <td>[0.21265466511249542, 0.012709632515907288, -0...</td>\n",
       "      <td>[-0.047112684696912766, 0.15232017636299133, 0...</td>\n",
       "      <td>[0.007619432173669338, 0.12938520312309265, 0....</td>\n",
       "      <td>Video-Play</td>\n",
       "      <td>Video-Play</td>\n",
       "      <td>Video-Play</td>\n",
       "      <td>Video-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>打开播放广州降水的报告</td>\n",
       "      <td>打开 播放 广州 降水 报告</td>\n",
       "      <td>[0.06798224151134491, -0.09668520838022232, 0....</td>\n",
       "      <td>[0.27344685792922974, 0.031061727553606033, -0...</td>\n",
       "      <td>[-0.05623794347047806, 0.1980530321598053, 0.0...</td>\n",
       "      <td>[0.005873105954378843, 0.17962105572223663, 0....</td>\n",
       "      <td>FilmTele-Play</td>\n",
       "      <td>FilmTele-Play</td>\n",
       "      <td>FilmTele-Play</td>\n",
       "      <td>FilmTele-Play</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text                     text_segs  \\\n",
       "0                 回放CCTV2的消费主张                   回放 CCTV2 消费   \n",
       "1                    给我打开玩具房的灯                     打开 玩具 房 灯   \n",
       "2               循环播放赵本山的小品相亲来听             循环 播放 赵本山 小品 相亲 听   \n",
       "3     15号上午10点带孩子去海洋馆的行程帮我制定下。  15 号 上午 10 点带 孩子 海洋馆 行程 制定 。   \n",
       "4                   把智能扫地机器人关掉                  智能 扫地 机器人 关掉   \n",
       "...                        ...                           ...   \n",
       "2995      是否能找一首2019年的抖音歌曲播放下呢            找 一首 2019 抖音 歌曲 播放   \n",
       "2996        下午三点有哪个台放大话西游吗帮我看下                 下午 三点 台放 大话西游   \n",
       "2997          随机播放一首古筝弹奏的曲子可以吗             随机 播放 一首 古筝 弹奏 曲子   \n",
       "2998           美食纪录片螃蟹的征途给我找一下                美食 纪录片 螃蟹 征途 找   \n",
       "2999               打开播放广州降水的报告                打开 播放 广州 降水 报告   \n",
       "\n",
       "                                            text_w2v_50  \\\n",
       "0     [0.036894213408231735, -0.09735322743654251, 0...   \n",
       "1     [0.053586602210998535, -0.09181060642004013, 0...   \n",
       "2     [0.06058083102107048, -0.027346991002559662, -...   \n",
       "3     [0.10507967323064804, -0.3613370656967163, 0.1...   \n",
       "4     [0.07013531774282455, -0.10136409103870392, 0....   \n",
       "...                                                 ...   \n",
       "2995  [0.048687893897295, -0.06284000724554062, -0.0...   \n",
       "2996  [0.10081005096435547, -0.16935856640338898, 0....   \n",
       "2997  [0.04146405681967735, -0.005537357181310654, -...   \n",
       "2998  [0.04323325678706169, -0.07966790348291397, 0....   \n",
       "2999  [0.06798224151134491, -0.09668520838022232, 0....   \n",
       "\n",
       "                                            text_w2v_70  \\\n",
       "0     [0.15702958405017853, -0.02909264713525772, -0...   \n",
       "1     [0.1797219067811966, -0.005513092502951622, -0...   \n",
       "2     [0.24930541217327118, 0.07945393770933151, -0....   \n",
       "3     [0.30579033493995667, -0.15630006790161133, 0....   \n",
       "4     [0.20975342392921448, -0.004705200903117657, -...   \n",
       "...                                                 ...   \n",
       "2995  [0.4206104576587677, 0.10067712515592575, -0.3...   \n",
       "2996  [0.19554200768470764, -0.038734305649995804, -...   \n",
       "2997  [0.304779976606369, 0.108954519033432, -0.2450...   \n",
       "2998  [0.21265466511249542, 0.012709632515907288, -0...   \n",
       "2999  [0.27344685792922974, 0.031061727553606033, -0...   \n",
       "\n",
       "                                           text_w2v_100  \\\n",
       "0     [-0.037246935069561005, 0.11769197136163712, 0...   \n",
       "1     [-0.0409448966383934, 0.1435110867023468, 0.02...   \n",
       "2     [-0.030159713700413704, 0.1654077023267746, -0...   \n",
       "3     [-0.11538441479206085, 0.2785932123661041, 0.1...   \n",
       "4     [-0.05659368261694908, 0.1639595478773117, 0.0...   \n",
       "...                                                 ...   \n",
       "2995  [-0.0762188658118248, 0.25765904784202576, 0.0...   \n",
       "2996  [-0.051506027579307556, 0.166267529129982, 0.0...   \n",
       "2997  [-0.041685521602630615, 0.16562624275684357, 5...   \n",
       "2998  [-0.047112684696912766, 0.15232017636299133, 0...   \n",
       "2999  [-0.05623794347047806, 0.1980530321598053, 0.0...   \n",
       "\n",
       "                                           text_w2v_120  \\\n",
       "0     [0.009291189722716808, 0.10824751853942871, 0....   \n",
       "1     [0.013976670801639557, 0.14177896082401276, 0....   \n",
       "2     [-0.01383722573518753, 0.12671895325183868, 0....   \n",
       "3     [0.05573185160756111, 0.32761403918266296, 0.0...   \n",
       "4     [0.012684157118201256, 0.1588975340127945, 0.0...   \n",
       "...                                                 ...   \n",
       "2995  [0.00036368612200021744, 0.2149602621793747, 0...   \n",
       "2996  [0.01222950592637062, 0.16824771463871002, 0.0...   \n",
       "2997  [0.0006796050001867115, 0.1478983461856842, 0....   \n",
       "2998  [0.007619432173669338, 0.12938520312309265, 0....   \n",
       "2999  [0.005873105954378843, 0.17962105572223663, 0....   \n",
       "\n",
       "                  Y_pred_50              Y_pred_70             Y_pred_100  \\\n",
       "0                Video-Play             Video-Play             Video-Play   \n",
       "1     HomeAppliance-Control  HomeAppliance-Control  HomeAppliance-Control   \n",
       "2                Music-Play             Music-Play             Music-Play   \n",
       "3              Alarm-Update           Alarm-Update           Alarm-Update   \n",
       "4     HomeAppliance-Control  HomeAppliance-Control  HomeAppliance-Control   \n",
       "...                     ...                    ...                    ...   \n",
       "2995             Music-Play             Music-Play             Music-Play   \n",
       "2996           Alarm-Update           Alarm-Update           Alarm-Update   \n",
       "2997             Music-Play             Music-Play             Music-Play   \n",
       "2998             Video-Play             Video-Play             Video-Play   \n",
       "2999          FilmTele-Play          FilmTele-Play          FilmTele-Play   \n",
       "\n",
       "                 Y_pred_120  \n",
       "0                Video-Play  \n",
       "1     HomeAppliance-Control  \n",
       "2                Music-Play  \n",
       "3              Alarm-Update  \n",
       "4     HomeAppliance-Control  \n",
       "...                     ...  \n",
       "2995             Music-Play  \n",
       "2996           Alarm-Update  \n",
       "2997             Music-Play  \n",
       "2998             Video-Play  \n",
       "2999          FilmTele-Play  \n",
       "\n",
       "[3000 rows x 10 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a3f1fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR输出结果文件\n",
    "#在https://competition.coggle.club/上的结果是0.531000\n",
    "with open(\"results\\\\w2v\\\\LR\\\\50.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_50\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.533333\n",
    "with open(\"results\\\\w2v\\\\LR\\\\70.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_70\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.519000\n",
    "with open(\"results\\\\w2v\\\\LR\\\\100.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_100\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.524667\n",
    "with open(\"results\\\\w2v\\\\LR\\\\120.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_120\"]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "14ccd388",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_50 = LinearSVC(C=1.0)\n",
    "svm_70 = LinearSVC(C=1.0)\n",
    "svm_100 = LinearSVC(C=1.0)\n",
    "svm_120 = LinearSVC(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a51ce604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_50.fit(X_50,Y_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "29deb21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_70.fit(X_70,Y_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9c0b9956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_100.fit(X_100,Y_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2707c98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_120.fit(X_120,Y_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d4f335f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_50_svm = svm_50.predict(X_pred_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f352d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_70_svm = svm_70.predict(X_pred_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "82826338",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_100_svm = svm_100.predict(X_pred_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f427bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_120_svm = svm_120.predict(X_pred_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8e291b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Y_pred_50_SVM\"] = Y_pred_50_svm\n",
    "test_data[\"Y_pred_70_SVM\"] = Y_pred_70_svm\n",
    "test_data[\"Y_pred_100_SVM\"] = Y_pred_100_svm\n",
    "test_data[\"Y_pred_120_SVM\"] = Y_pred_120_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a857a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM输出结果文件\n",
    "#在https://competition.coggle.club/上的结果是0.564333\n",
    "with open(\"results\\\\w2v\\\\SVM\\\\50.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_50_SVM\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.564000\n",
    "with open(\"results\\\\w2v\\\\SVM\\\\70.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_70_SVM\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.563667\n",
    "with open(\"results\\\\w2v\\\\SVM\\\\100.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_100_SVM\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.568000\n",
    "with open(\"results\\\\w2v\\\\SVM\\\\120.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_120_SVM\"]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d535d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_50 = tree.DecisionTreeClassifier(criterion='gini', \n",
    "                                         max_depth=None,\n",
    "                                         min_samples_leaf=1,\n",
    "                                         ccp_alpha=0.0)\n",
    "dt_70 = tree.DecisionTreeClassifier(criterion='gini', \n",
    "                                         max_depth=None,\n",
    "                                         min_samples_leaf=1,\n",
    "                                         ccp_alpha=0.0)\n",
    "dt_100 = tree.DecisionTreeClassifier(criterion='gini', \n",
    "                                         max_depth=None,\n",
    "                                         min_samples_leaf=1,\n",
    "                                         ccp_alpha=0.0)\n",
    "dt_120 = tree.DecisionTreeClassifier(criterion='gini', \n",
    "                                         max_depth=None,\n",
    "                                         min_samples_leaf=1,\n",
    "                                         ccp_alpha=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e2648bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_50.fit(X_50,Y_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "03dd6d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_70.fit(X_70,Y_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8f989588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_100.fit(X_100,Y_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6f583a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_120.fit(X_120,Y_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "aea0fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_50_dt = dt_50.predict(X_pred_50)\n",
    "Y_pred_70_dt = dt_70.predict(X_pred_70)\n",
    "Y_pred_100_dt = dt_100.predict(X_pred_100)\n",
    "Y_pred_120_dt = dt_120.predict(X_pred_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "39003e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Y_pred_50_DT\"] = Y_pred_50_dt\n",
    "test_data[\"Y_pred_70_DT\"] = Y_pred_70_dt\n",
    "test_data[\"Y_pred_100_DT\"] = Y_pred_100_dt\n",
    "test_data[\"Y_pred_120_DT\"] = Y_pred_120_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b27271cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT输出结果文件\n",
    "#在https://competition.coggle.club/上的结果是0.564333\n",
    "with open(\"results\\\\w2v\\\\DT\\\\50.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_50_DT\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.565000\n",
    "with open(\"results\\\\w2v\\\\DT\\\\70.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_70_DT\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.557333\n",
    "with open(\"results\\\\w2v\\\\DT\\\\100.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_100_DT\"]+\"\\n\")\n",
    "#在https://competition.coggle.club/上的结果是0.576667\n",
    "with open(\"results\\\\w2v\\\\DT\\\\120.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_120_DT\"]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "综上实验结果：\n",
    "    1. 词向量的维度会影响到模型精度吗？会的，测试了50,70,100,120维度的词向量，会影响到结果。LR的结果显示70的维度最好，SVM和DT的结果是120的维度最好\n",
    "    2. 词向量编码后使用树模型和LR，谁的精度高，为什么？在我的结果中，树模型的结果比LR好。其原因我认为是因为，逻辑回归更适合解决线性问题，但是文本的分类\n",
    "    一般来说不是线性的，因此使用树模型或者SVM效果更佳。\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8f52606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用开源的word2vec词向量：来源https://github.com/Flywolfs/Chinese-Word-Vectors\n",
    "word2vec_path = \"word2vec\\\\sgns.zhihu.word\\\\sgns.zhihu.word\"\n",
    "zhi_vec_depth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5bb2f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "zhihu_w2v = {}\n",
    "with open(word2vec_path,\"r\",encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        line = line.rstrip()\n",
    "        seps = line.split(\" \")\n",
    "        word = seps[0]\n",
    "        vec = seps[1:]\n",
    "        zhihu_w2v[seps[0]] = np.array(vec,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4f4763d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#平均句向量\n",
    "def sent_vec_opensource(sent,w2v=None):\n",
    "    sent_segs = sent.split()\n",
    "    #对付NaN\n",
    "    mean_sent_vec = np.zeros((300,),dtype=float)+0.00001\n",
    "    for seg in sent_segs:\n",
    "        if seg in w2v:\n",
    "            mean_sent_vec += w2v[seg]\n",
    "    #对付inf,因为有的句子分词+去停词后为空字符串\n",
    "    if len(sent_segs) == 0:\n",
    "        mean_sent_vec = mean_sent_vec\n",
    "    else:\n",
    "        mean_sent_vec = mean_sent_vec/len(sent_segs)\n",
    "    mean_sent_vec = mean_sent_vec.tolist()\n",
    "    return mean_sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0749323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"text_w2v_zhihu\"] = train_data[\"text_segs\"].apply(sent_vec_opensource,w2v=zhihu_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "bf988f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"text_w2v_zhihu\"] = test_data[\"text_segs\"].apply(sent_vec_opensource,w2v=zhihu_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "32160c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_zhihu = LinearSVC(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2855edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12100, 300) (12100,)\n"
     ]
    }
   ],
   "source": [
    "X_300 = np.array(train_data[\"text_w2v_zhihu\"].tolist()).reshape(len(train_data[\"text_w2v_zhihu\"]),300)\n",
    "Y_300 = train_data[\"label\"].to_numpy()\n",
    "print(X_300.shape,Y_300.shape)\n",
    "# X,Y = remove_nan(X,Y,vector_size=50)\n",
    "# print(X.shape,Y.shape)\n",
    "svm_zhihu.fit(X_300,Y_300)\n",
    "X_pred_300 = np.array(test_data[\"text_w2v_zhihu\"].tolist()).reshape(len(test_data[\"text_w2v_zhihu\"]),300)\n",
    "Y_pred_300_svm_zhihu = svm_zhihu.predict(X_pred_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7d48ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Y_pred_300_SVM_ZHIHU\"] = Y_pred_300_svm_zhihu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "51ee8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在https://competition.coggle.club/上的结果是0.747000\n",
    "with open(\"results\\\\w2v\\\\SVM\\\\300.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"Y_pred_300_SVM_ZHIHU\"]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2919650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle",
   "language": "python",
   "name": "paddle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
