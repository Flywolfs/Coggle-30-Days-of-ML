{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07370d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv', sep='\\t', header=None)\n",
    "test_data = pd.read_csv('test.csv', sep='\\t', header=None)\n",
    "train_data.columns = [\"text\",\"label\"]\n",
    "test_data.columns = [\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb621d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2_id = {}\n",
    "classes = []\n",
    "index = 0\n",
    "for i in range(0,len(train_data)):\n",
    "    label = train_data.iloc[i][\"label\"]\n",
    "    if label not in label_2_id:\n",
    "        classes.append(label)\n",
    "        label_2_id[label] = index\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87ed6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2_label = {}\n",
    "for label in label_2_id:\n",
    "    index_2_label[label_2_id[label]] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c44cbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_words = []\n",
    "for _class in classes:\n",
    "    label_words.append([_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "729e472e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Travel-Query'],\n",
       " ['Music-Play'],\n",
       " ['FilmTele-Play'],\n",
       " ['Video-Play'],\n",
       " ['Radio-Listen'],\n",
       " ['HomeAppliance-Control'],\n",
       " ['Weather-Query'],\n",
       " ['Alarm-Update'],\n",
       " ['Calendar-Query'],\n",
       " ['TVProgram-Play'],\n",
       " ['Audio-Play'],\n",
       " ['Other']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560d3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\generation_utils.py:27: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "def load_local_dataset(data=None, split=\"train\"):\n",
    "    dataset = []\n",
    "    if split == \"train\":\n",
    "        for i in range(0,len(data)):\n",
    "            dataset.append(InputExample(guid=i,text_a=data.iloc[i][\"text\"],label=label_2_id[data.iloc[i][\"label\"]]))\n",
    "    else:\n",
    "        for i in range(0,len(data)):\n",
    "            dataset.append(InputExample(guid=i,text_a=data.iloc[i][\"text\"]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb158003",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['train'] = load_local_dataset(train_data,split=\"train\")\n",
    "dataset['test'] = load_local_dataset(test_data,split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9bf76e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at G:\\deep_learning\\models\\chinese_wwm_ext_pytorch\\ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from openprompt.plms import load_plm\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"G:\\\\deep_learning\\\\models\\\\chinese_wwm_ext_pytorch\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a334466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import ManualTemplate\n",
    "promptTemplate = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"} 这句话的类别是{\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1fcd8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import ManualTemplate\n",
    "promptTemplate = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"} 请输出前面这句话对应的类别是{\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5b5fbe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import ManualVerbalizer\n",
    "myverbalizer = ManualVerbalizer(tokenizer, num_classes=12,\n",
    "                        label_words=label_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "162adfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 12100it [00:07, 1552.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from openprompt import PromptDataLoader\n",
    "train_data_loader = PromptDataLoader(\n",
    "    dataset = dataset[\"train\"],\n",
    "    tokenizer = tokenizer,\n",
    "    template = promptTemplate,\n",
    "    tokenizer_wrapper_class=WrapperClass,\n",
    "    max_seq_length=64,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ca7cf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 3000it [00:01, 1555.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from openprompt import PromptDataLoader\n",
    "test_data_loader = PromptDataLoader(\n",
    "    dataset = dataset[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    template = promptTemplate,\n",
    "    tokenizer_wrapper_class=WrapperClass,\n",
    "    max_seq_length=64,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7811168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt import PromptForClassification\n",
    "prompt_model  = PromptForClassification(plm=plm,template=promptTemplate, verbalizer=myverbalizer, freeze_plm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3912222",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "if use_cuda:\n",
    "    prompt_model =  prompt_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9bbfea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the training is standard\n",
    "import torch\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# it's always good practice to set no decay to biase and LayerNorm parameters\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc06ec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06aef4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 4.581607818603516\n",
      "Epoch 0, average loss: 0.5449433169492027\n",
      "Epoch 0, average loss: 0.4169382690959195\n",
      "Epoch 0, average loss: 0.3813562760351608\n",
      "Epoch 1, average loss: 0.20896898582577705\n",
      "Epoch 1, average loss: 0.17732031825089864\n",
      "Epoch 1, average loss: 0.1835580710506085\n",
      "Epoch 1, average loss: 0.19000956037124953\n",
      "Epoch 2, average loss: 0.016772496979683638\n",
      "Epoch 2, average loss: 0.1047553962425274\n",
      "Epoch 2, average loss: 0.12468694973654013\n",
      "Epoch 2, average loss: 0.12979972778606716\n",
      "Epoch 3, average loss: 0.05020926636643708\n",
      "Epoch 3, average loss: 0.11516877175673988\n",
      "Epoch 3, average loss: 0.11737516069886192\n",
      "Epoch 3, average loss: 0.11143055011669409\n",
      "Epoch 4, average loss: 0.10534731857478619\n",
      "Epoch 4, average loss: 0.06695033097126082\n",
      "Epoch 4, average loss: 0.07712411430075368\n",
      "Epoch 4, average loss: 0.08809662606996571\n",
      "Epoch 5, average loss: 0.11918643489480019\n",
      "Epoch 5, average loss: 0.09508560088864874\n",
      "Epoch 5, average loss: 0.0973258451616281\n",
      "Epoch 5, average loss: 0.11451741433255251\n",
      "Epoch 6, average loss: 0.056781507562845945\n",
      "Epoch 6, average loss: 0.09393456126289333\n",
      "Epoch 6, average loss: 0.09981097301294206\n",
      "Epoch 6, average loss: 0.11162776431370995\n",
      "Epoch 7, average loss: 0.02557707577943802\n",
      "Epoch 7, average loss: 0.10118046281722319\n",
      "Epoch 7, average loss: 0.08526303578573878\n",
      "Epoch 7, average loss: 0.08652065645048351\n",
      "Epoch 8, average loss: 0.06474903365597129\n",
      "Epoch 8, average loss: 0.05894257076650712\n",
      "Epoch 8, average loss: 0.06069121828203615\n",
      "Epoch 8, average loss: 0.06737445838346966\n",
      "Epoch 9, average loss: 0.13083826936781406\n",
      "Epoch 9, average loss: 0.06874019381111972\n",
      "Epoch 9, average loss: 0.06226958006249837\n",
      "Epoch 9, average loss: 0.06451694097183722\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    tot_loss = 0\n",
    "    for step, inputs in enumerate(train_data_loader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        logits = prompt_model(inputs)\n",
    "        labels = inputs['label']\n",
    "        loss = loss_func(logits, labels)\n",
    "        loss.backward()\n",
    "        tot_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step %100 ==1:\n",
    "            print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7835cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds = []\n",
    "for step, inputs in enumerate(test_data_loader):\n",
    "    if use_cuda:\n",
    "        inputs = inputs.cuda()\n",
    "    logits = prompt_model(inputs)\n",
    "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4011bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_by_promptbert = []\n",
    "for pred in allpreds:\n",
    "    pred_by_promptbert.append(index_2_label[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08e3ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"pred_by_promptbert\"] = pred_by_promptbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a4b6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在https://competition.coggle.club/上的结果是0.797000\n",
    "#这个是使用开源bert,max_len=64,batch_size=32,epoch=10,prompt是：这句话的类别是{\"mask\"}\n",
    "with open(\"results\\\\bert_prompt_64_32_10.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"pred_by_promptbert\"]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29db6841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在https://competition.coggle.club/上的结果是0.796333\n",
    "#这个是使用开源bert,max_len=64,batch_size=32,epoch=10,prompt是：请输出前面这句话对应的类别是{\"mask\"}\n",
    "with open(\"results\\\\bert_prompt_64_32_10_2.txt\",\"w\") as f:\n",
    "    f.write(\"ID,Target\\n\")\n",
    "    for i in range(len(test_data)):\n",
    "        f.write(str(i+1)+\",\"+test_data.iloc[i][\"pred_by_promptbert\"]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2ec6db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt分类比BERT分类相比，在精度上有什么区别？从效果上看没有BERT分类效果好\n",
    "#自定义prompt对模型的精度是否有影响？可以尝试2种不同的prompt。对模型精度有影响，但是不大，肯定和我的prompt设计有关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37bda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
